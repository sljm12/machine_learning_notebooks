{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2 for Data Augementation",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1k1LS-19hgpPgGvBdZWEH6hHNwbluUxaa",
      "authorship_tag": "ABX9TyOOvkKq4Ag2E3mr9izJqvoX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sljm12/machine_learning_notebooks/blob/master/GPT2_for_Data_Augementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oSmmHkkQoLB"
      },
      "source": [
        "Want to investigate using GPT2 for Data Augenmentation\n",
        "\n",
        "https://huggingface.co/blog/how-to-generate\n",
        "\n",
        "https://arxiv.org/pdf/2003.02245v1.pdf\n",
        "\n",
        "https://github.com/falloutdurham/beginners-pytorch-deep-learning/blob/master/chapter9/Chapter9.5.ipynb\n",
        "\n",
        "https://docs.fast.ai/tutorial.transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOAKjcnwLoKZ"
      },
      "source": [
        "!pip -qq install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odh2XaOQQNLf"
      },
      "source": [
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup\n",
        "from tqdm import tqdm, trange\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrZqzGeWPHdw",
        "outputId": "e08f6046-0454-462a-91b8-66f9a40115df"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2',num_beams=4)\n",
        "\n",
        "input_ids = tokenizer.encode(\"The night is still young, as the world sleeps \",return_tensors='pt')\n",
        "\n",
        "\n",
        "generated = model.generate(input_ids, max_length=100, num_beams=5, early_stopping=True, no_repeat_ngram_size=2, num_return_sequences=5, top_k=0, top_p=0.9)\n",
        "\n",
        "for i in generated:\n",
        "  sequence = tokenizer.decode(i, skip_special_tokens=True)\n",
        "  print(sequence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The night is still young, as the world sleeps  and there is no sign of the sun rising. The sun is rising, and the moon is falling. There is nothing to be seen, but the sky is full of stars.\n",
            "The sun has risen. It is time for us to go back to sleep. We are going to wake up in the morning and we will be able to look at the stars and see what is going on around us. This is the time we need to\n",
            "The night is still young, as the world sleeps  and there is no sign of the sun rising. The sun is rising, and the moon is falling. There is nothing to be seen, but the sky is full of stars.\n",
            "The sun has risen. It is time for us to go back to sleep. We are going to wake up in the morning and we will be able to look at the stars and see what is going on around us. This is the time when we should\n",
            "The night is still young, as the world sleeps  and there is no sign of the sun rising. The sun is rising, and the moon is falling. There is nothing to be seen, but the sky is full of stars.\n",
            "The sun has risen. It is time for us to go back to sleep. We are going to wake up in the morning and we will be able to look at the stars and see what is going on around us. This is the time when we are\n",
            "The night is still young, as the world sleeps  and there is no sign of the sun rising. The sun is rising, and the moon is falling. There is nothing to be seen, but the sky is full of stars.\n",
            "The sun has risen. It is time for us to go back to sleep. We are going to wake up in the morning and we will be able to look at the stars and see what is going on around us. This is the time when we can\n",
            "The night is still young, as the world sleeps  and there is no sign of the sun rising. The sun is rising, and the moon is falling. There is nothing to be seen, but the sky is full of stars.\n",
            "The sun has risen. It is time for us to go back to sleep. We are going to wake up in the morning and we will be able to look at the stars and see what is going on around us. This is the time when we need\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCapT7UKLjxQ"
      },
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2',num_beams=4)\n",
        "\n",
        "generated = tokenizer.encode(\"Stephen Lee has two kids Chloe and Caleb.\")\n",
        "context = torch.tensor([generated])\n",
        "past = None\n",
        "\n",
        "for i in range(100):\n",
        "    output, past = model(context, past=past)\n",
        "    token = torch.argmax(output[..., -1, :])\n",
        "\n",
        "    generated += [token.tolist()]\n",
        "    context = token.unsqueeze(0)\n",
        "\n",
        "sequence = tokenizer.decode(generated)\n",
        "\n",
        "print(sequence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72VsMje0Lx09"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpXU5vwxpVyX"
      },
      "source": [
        "# Finetuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcf-2bLVqFT-"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Zb_n4aVoPg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23320553-7419-471a-d0b1-0b352006552a"
      },
      "source": [
        "!wget -qq https://www.dropbox.com/s/duoi46s4db28xac/news-category-dataset.zip\n",
        "!unzip news-category-dataset.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  news-category-dataset.zip\n",
            "replace News_Category_Dataset_v2.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxH92By1RnIp"
      },
      "source": [
        "import json\n",
        "from  pathlib import Path\n",
        "data = []\n",
        "with open(\"/content/News_Category_Dataset_v2.json\") as f:\n",
        "  lines = f.readlines()\n",
        "  for l in lines:\n",
        "    j=json.loads(l)\n",
        "    data.append(j)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbHgcU2pR4YF"
      },
      "source": [
        "df=pd.DataFrame(data=data)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ie78g4_hSO4D",
        "outputId": "d011025d-32f5-46e5-9c4f-7604ad330e81"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
              "      <td>Melissa Jeltsen</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
              "      <td>She left her husband. He killed their children...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category  ...        date\n",
              "0          CRIME  ...  2018-05-26\n",
              "1  ENTERTAINMENT  ...  2018-05-26\n",
              "2  ENTERTAINMENT  ...  2018-05-26\n",
              "3  ENTERTAINMENT  ...  2018-05-26\n",
              "4  ENTERTAINMENT  ...  2018-05-26\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ5sdAvcc_t1",
        "outputId": "60d97610-fd1f-48f1-b0ad-aa9eec571524"
      },
      "source": [
        "df[\"category\"].unique()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['CRIME', 'ENTERTAINMENT', 'WORLD NEWS', 'IMPACT', 'POLITICS',\n",
              "       'WEIRD NEWS', 'BLACK VOICES', 'WOMEN', 'COMEDY', 'QUEER VOICES',\n",
              "       'SPORTS', 'BUSINESS', 'TRAVEL', 'MEDIA', 'TECH', 'RELIGION',\n",
              "       'SCIENCE', 'LATINO VOICES', 'EDUCATION', 'COLLEGE', 'PARENTS',\n",
              "       'ARTS & CULTURE', 'STYLE', 'GREEN', 'TASTE', 'HEALTHY LIVING',\n",
              "       'THE WORLDPOST', 'GOOD NEWS', 'WORLDPOST', 'FIFTY', 'ARTS',\n",
              "       'WELLNESS', 'PARENTING', 'HOME & LIVING', 'STYLE & BEAUTY',\n",
              "       'DIVORCE', 'WEDDINGS', 'FOOD & DRINK', 'MONEY', 'ENVIRONMENT',\n",
              "       'CULTURE & ARTS'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hkci8-Xa7-9"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2',num_beams=4)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmmzgXlhSP8r"
      },
      "source": [
        "class NewsDataSet(Dataset):\n",
        "    \n",
        "    def __init__(self, dataframe, control_code, truncate=False, gpt2_type=\"gpt2\", max_length=768):\n",
        "\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
        "        self.tweets = []\n",
        "\n",
        "        # This uses the same CSV of Sentiment140 that we created in Chapter 5\n",
        "        \n",
        "        for i in dataframe.itertuples():\n",
        "              self.tweets.append(torch.tensor(\n",
        "                  self.tokenizer.encode(f\"<|{control_code}|>{i[1]}<|sep|>{i[2]}<|endoftext|>\")\n",
        "              ))\n",
        "                \n",
        "        if truncate:\n",
        "            self.tweets = self.tweets[:20000]\n",
        "        self.tweet_count = len(self.tweets)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.tweet_count\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        return self.tweets[item]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6AvjKRXZ2kX"
      },
      "source": [
        "dataset = NewsDataSet(df, 'newsheader')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-zldO8GZ6lp",
        "outputId": "093667b8-f3e4-4d96-d310-509468728713"
      },
      "source": [
        "dataset.__getitem__(1)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   27,    91, 10827, 25677,    91,    29,  8743,  4176,  5302,  1040,\n",
              "         6031,   489,    78,   843,  8047,    88,  9986,  1114,   383,  2864,\n",
              "         2159,  5454,   338, 15934, 10940, 50256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05_leetdpgjc",
        "outputId": "7319bca4-1b1a-4ed5-85e6-ba78ff0b5867"
      },
      "source": [
        "dataset.__len__()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200853"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2X8ySXu6axrE",
        "outputId": "361bd4ef-3e63-40ec-bd04-bcccc8def466"
      },
      "source": [
        "tokenizer.decode(dataset.__getitem__(1))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<|newsheader|>ENTERTAINMENT<|sep|>Will Smith Joins Diplo And Nicky Jam For The 2018 World Cup's Official Song<|endoftext|>\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f6M1mwXa1zB"
      },
      "source": [
        "def pack_tensor(new_tensor, packed_tensor, max_seq_len):\n",
        "    if packed_tensor is None:\n",
        "        return new_tensor, True, None\n",
        "    if new_tensor.size()[1] + packed_tensor.size()[1] > max_seq_len:\n",
        "        return packed_tensor, False, new_tensor\n",
        "    else:\n",
        "        packed_tensor = torch.cat([new_tensor, packed_tensor[:, 1:]], dim=1)\n",
        "        return packed_tensor, True, None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sF1AUnmicAfy"
      },
      "source": [
        "def train(\n",
        "    dataset,\n",
        "    model,\n",
        "    tokenizer,\n",
        "    batch_size=16,\n",
        "    epochs=4,\n",
        "    lr=2e-5,\n",
        "    max_seq_len=400,\n",
        "    warmup_steps=5000,\n",
        "    gpt2_type=\"gpt2\",\n",
        "    device=\"cuda\",\n",
        "    output_dir=\".\",\n",
        "    output_prefix=\"wreckgar\",\n",
        "    test_mode=False,\n",
        "    save_model_on_epoch=False,\n",
        "):\n",
        "\n",
        "    acc_steps = 100\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=lr)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=warmup_steps, num_training_steps=-1\n",
        "    )\n",
        "\n",
        "    train_dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    accumulating_batch_count = 0\n",
        "    input_tensor = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        print(f\"Training epoch {epoch}\")\n",
        "        for idx, entry in tqdm(enumerate(train_dataloader)):\n",
        "            (input_tensor, carry_on, remainder) = pack_tensor(entry, input_tensor, 768)\n",
        "\n",
        "            if carry_on and idx != len(train_dataloader) - 1:\n",
        "                continue\n",
        "\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            outputs = model(input_tensor, labels=input_tensor)\n",
        "            loss = outputs[0]\n",
        "            loss.backward()\n",
        "\n",
        "            if (accumulating_batch_count % batch_size) == 0:\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                model.zero_grad()\n",
        "\n",
        "            accumulating_batch_count += 1\n",
        "            input_tensor = None\n",
        "        if save_model_on_epoch:\n",
        "            torch.save(\n",
        "                model.state_dict(),\n",
        "                os.path.join(output_dir, f\"{output_prefix}-{epoch}.pt\"),\n",
        "            )\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYtrsOM51UWu"
      },
      "source": [
        "!mkdir \"/content/trained_models\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAuxYPUGcTDe",
        "outputId": "06836245-8752-4b57-8b13-493be589c38f"
      },
      "source": [
        "model = train(\n",
        "    dataset,\n",
        "    GPT2LMHeadModel.from_pretrained(\"gpt2\"),\n",
        "    GPT2Tokenizer.from_pretrained(\"gpt2\"),\n",
        "    batch_size=16,\n",
        "    epochs=3,\n",
        "    lr=3e-5,\n",
        "    max_seq_len=140,\n",
        "    warmup_steps=5000,\n",
        "    gpt2_type=\"gpt2\",\n",
        "    device=\"cuda\",\n",
        "    output_dir=\"/content/trained_models\",\n",
        "    output_prefix=\"gpt_newsheadlines_categories\",\n",
        "    save_model_on_epoch=True\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200853it [40:33, 82.53it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200853it [40:38, 82.37it/s]\n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training epoch 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200853it [40:39, 82.32it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLOkay4ZiNaI"
      },
      "source": [
        "nmodel.save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMVsWAwscXTw"
      },
      "source": [
        "def generate(\n",
        "    model,\n",
        "    tokenizer,\n",
        "    prompt,\n",
        "    entry_count=10,\n",
        "    entry_length=100,\n",
        "    top_p=0.8,\n",
        "    temperature=1.,\n",
        "):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    generated_num = 0\n",
        "    generated_list = []\n",
        "\n",
        "    filter_value = -float(\"Inf\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for entry_idx in trange(entry_count):\n",
        "\n",
        "            entry_finished = False\n",
        "\n",
        "            generated = torch.tensor(tokenizer.encode(prompt)).to(\"cuda\").unsqueeze(0)\n",
        "\n",
        "            # Using top-p (nucleus sampling): https://github.com/huggingface/transformers/blob/master/examples/run_generation.py\n",
        "\n",
        "            for i in range(entry_length):\n",
        "                outputs = model(generated, labels=generated)\n",
        "                loss, logits = outputs[:2]\n",
        "                logits = logits[:, -1, :] / (temperature if temperature > 0 else 1.0)\n",
        "\n",
        "                sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "                cumulative_probs = torch.cumsum(\n",
        "                    F.softmax(sorted_logits, dim=-1), dim=-1\n",
        "                )\n",
        "\n",
        "                sorted_indices_to_remove = cumulative_probs > top_p\n",
        "                sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[\n",
        "                    ..., :-1\n",
        "                ].clone()\n",
        "                sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "                indices_to_remove = sorted_indices[sorted_indices_to_remove]\n",
        "                logits[:, indices_to_remove] = filter_value\n",
        "\n",
        "                next_token = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1)\n",
        "                generated = torch.cat((generated, next_token), dim=1)\n",
        "\n",
        "                if next_token in tokenizer.encode(\"<|endoftext|>\"):\n",
        "                    entry_finished = True\n",
        "\n",
        "                if entry_finished:\n",
        "\n",
        "                    generated_num = generated_num + 1\n",
        "\n",
        "                    output_list = list(generated.to(\"cpu\").squeeze().numpy())\n",
        "                    output_text = tokenizer.decode(output_list)\n",
        "\n",
        "                    generated_list.append(output_text)\n",
        "                    break\n",
        "            \n",
        "            if not entry_finished:\n",
        "                output_list = list(generated.to(\"cpu\").squeeze().numpy())\n",
        "                output_text = f\"{tokenizer.decode(output_list)}<|endoftext|>\" \n",
        "                generated_list.append(output_text)\n",
        "                \n",
        "    return generated_list"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrHjNuC2dv0j",
        "outputId": "89ec0449-5819-4465-deaa-e7a4f4a1ede3"
      },
      "source": [
        "generated_tweets = generate(model.to('cuda'), GPT2Tokenizer.from_pretrained(\"gpt2\"),\"<|newsheadlines|>POLITICS<|sep|>\",entry_count=10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  3.46it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEn2YFIPimzD",
        "outputId": "47b645a6-13e0-4019-d7e9-8fae96b69fb9"
      },
      "source": [
        "for i in generated_tweets:\n",
        "  print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<|newsheadlines|>POLITICS<|sep|>Speaker Paul Ryan Makes Retirement With $10 Million In Cash And Student Loans<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Anti-Semitic Twitter Posts At London Airport Linked To Orlando Shooting<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Clinton Campaign Donates $150,000 to DOJ To Combat 'Deadly' Anti-Immigrant Effort<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Hillary Clinton Is From A Meeting With A Young Girl<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Sen. Kirsten Gillibrand Offers Help For Gay Trump's Trans Rights<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Division Between OPPOSITE and WELLNESS CONNECTING</|sep|>Why Some Americans Think Hillary Clinton's 'Insecure' Email Address Will Be Bad For Hillary Clinton<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Russia Posters Are Done For Again: New 'House Of Cards' Trailer Looks Reasonable<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Politicians Who Won The Presidential Primary: Donald Trump, Mitt Romney<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Former Senate Majority Leader Johnny Isakson Says Wall Street Colluded With Trump Campaign, U.S. Government<|endoftext|>\n",
            "<|newsheadlines|>POLITICS<|sep|>Rick Perry Is On Dixie Cheating My Trump Presidency<|endoftext|>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxnJTPtxcpDu",
        "outputId": "57f14e97-4c6f-42f3-f779-07be3c4acf05"
      },
      "source": [
        "generated_tweets = generate(model.to('cuda'), GPT2Tokenizer.from_pretrained(\"gpt2\"),\"<|newsheadlines|>CRIME<|sep|>\",entry_count=10)\n",
        "for i in generated_tweets:\n",
        "  print(i)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<|newsheadlines|>CRIME<|sep|>FBI Warns FBI Offbeds Moving Kids From Hidalgo County, Texas<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Tears well up on U.S. News '' Investigators<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Why This Disease Is So Powerful For Human Rights<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>2 People Found Dead in Hotel Heist After Hostage Style Attack<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>North Carolina Boy Shot In Pinellas To Kill Woman<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Man Arrested On The Prom Back Of Cocaine, Meth, Heroin As Heroin In Dank Cages<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Cop Kills Son With Teenage Shootout At Heist 'God Bless America' Posters<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Philadelphia Allegedly Shot Two People Just Before Killing (VIDEO)<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Homicides Reportedly Found In New York's Pregnant Is An Infraction Of The NYPD<|endoftext|>\n",
            "<|newsheadlines|>CRIME<|sep|>Gunman Shot And Died At Pulse Cafe<|endoftext|>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHCYKGt5dGYX",
        "outputId": "740dba6e-48cf-4a60-bd96-d30651d13de6"
      },
      "source": [
        "generated_tweets = generate(model.to('cuda'), GPT2Tokenizer.from_pretrained(\"gpt2\"),\"<|newsheadlines|>SCIENCE<|sep|>\",entry_count=10)\n",
        "for i in generated_tweets:\n",
        "  print(i)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<|newsheadlines|>SCIENCE<|sep|>It's an Open Letter to One Girl's Dad Who Lost His Job To Cancer<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>Scientific Explanation: Engineers Did It<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>Plants Could Actually Make A Virus, Study Shows<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>Where Did the Supermassive Black Hole Exist?<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>Anomaly Could Be Found A Day After Living In The World's Most Lethal Superfund Site<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>An Astronaut's Complete Guide To Jupiter's New Slope, And The Fight Against Planet Earth<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>A Cell-Robust Plan To The Rescue Your Heart<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>Antarctic Climate Change Paves Way for Huge Dark Ocean On Pole<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>'Hunting In the Shadows': An Exploration of a Shaping Inner World<|endoftext|>\n",
            "<|newsheadlines|>SCIENCE<|sep|>New Marist Medical Center, Centennial Hall For Star Wars, Can Wait To Explore Life As An Open Space Station<|endoftext|>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGPs_UnXdHYD",
        "outputId": "a9da4ae3-cfd6-48ca-a0fd-2e56eb4bbd9d"
      },
      "source": [
        "generated_tweets = generate(model.to('cuda'), GPT2Tokenizer.from_pretrained(\"gpt2\"),\"<|newsheadlines|>WOLRD NEWS<|sep|>\",entry_count=10)\n",
        "for i in generated_tweets:\n",
        "  print(i)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:01<00:00,  5.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<|newsheadlines|>WOLRD NEWS<|sep|>J.D. Salinger's Native American Run Needs To Be 'Actively Blocking' The Slut Walk<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>Why I Would Absolutely Leave Politics In A Lazy Place<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>The Bay, Like Rivers Of The Sea<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>The Chaos Strikes<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>Johnnie Walker Poses A Big Price In Kratom Claim<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>Obama Spokeswoman And Republicans Are Sliding Over' Bashing On Trump<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>Alarming Photos Show Turtles Swimming In Water Of Tongue and Upright Nails<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>There's Something About When It Happens<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>Why A Girl Calls Him 'Bitch Boy' And Says 'Man In White'<|endoftext|>\n",
            "<|newsheadlines|>WOLRD NEWS<|sep|>Thousands Prompts First Big Move Against HIV/AIDS Accident<|endoftext|>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8MwLuVL8cUF",
        "outputId": "f17eeed0-ba11-4289-ea9e-5842f42d8a54"
      },
      "source": [
        "generated_tweets = generate(model.to('cuda'), GPT2Tokenizer.from_pretrained(\"gpt2\"),\"<|newsheadlines|>PARENTING<|sep|>\",entry_count=10)\n",
        "for i in generated_tweets:\n",
        "  print(i)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "<|newsheadlines|>PARENTING<|sep|>Meeting Church Leaders Who Are Taking Kids to Gospel Sites<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>The Path Ahead for Kids Who Are Growing Up In School Separated From Our Parents' Stories<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>5 Things You Need To Know About Making Parenting a Reality<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>When I Was Loving Grace, Someone Said, 'Go Away'<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>9 Things That You Can Learn From Parenting<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>10 Books That Can Make You Grow Up<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>This Kid Doesn't Care If He's A Star Of 'This Country'<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>10 Things You Must Know About Pregnancy and Toddlers<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>Parents Expect Their Kids To Call Out For Fears Of Fears Of Autism<|endoftext|>\n",
            "<|newsheadlines|>PARENTING<|sep|>Tim Herring's Dad Fails To Raise Kids He Didn't Need To: Orlando Asylum Center<|endoftext|>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23y5gNVwqCKd",
        "outputId": "1a991db1-4818-4131-eef6-038f16e7e5bc"
      },
      "source": [
        "!ls -lh /content/trained_models"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 487M\n",
            "-rw-r--r-- 1 root root 487M Nov 24 06:33 newsheadlines-0.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4vJeQBoBdt7"
      },
      "source": [
        "!cp /content/trained_models/gpt_newsheadlines_categories-2.pt '/content/drive/MyDrive/Machine Learning/'"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e7e0ImSBwwu"
      },
      "source": [
        "torch.save(model,\"/content/gpt_news.pt\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewKNTiiiHSVE",
        "outputId": "cb2bdd69-cfc1-43ad-e85e-b7e4fceb1446"
      },
      "source": [
        "!ls -lh /content"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 618M\n",
            "drwx------ 4 root root 4.0K Nov 24 06:52 drive\n",
            "-rw-r--r-- 1 root root 487M Nov 24 07:18 gpt_news.pt\n",
            "-rw-r--r-- 1 root root  81M Oct  1  2019 News_Category_Dataset_v2.json\n",
            "-rw-r--r-- 1 root root  26M Nov 24 05:19 news-category-dataset.zip\n",
            "-rw-r--r-- 1 root root  26M Nov 24 06:00 news-category-dataset.zip.1\n",
            "drwxr-xr-x 1 root root 4.0K Nov 13 17:33 sample_data\n",
            "drwxr-xr-x 2 root root 4.0K Nov 24 06:33 trained_models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "KPHD_jlOHjUz",
        "outputId": "a1c40e10-6b33-4c21-da70-0adf3f5c66cd"
      },
      "source": [
        "torch.load()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-79842e02b8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: load() missing 1 required positional argument: 'f'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb4K2YqEHot_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}