{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HuggingFace Bert Trump Biden Kamala Classifier .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sljm12/machine_learning_notebooks/blob/master/2020USElection/HuggingFace_Bert_Trump_Biden_Kamala_Classifier_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMg9tEpwxP1Z"
      },
      "source": [
        "## Intro ##\n",
        "This notebook uses Hugging Faces TFBertForSequenceClassification to do speaker identification based on the US election speeches.\n",
        "\n",
        "https://github.com/ralphbrooks/tensorflow-tutorials/blob/master/2-Sentiment-Classification-with-BERT.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Rl1PgcCV9G",
        "outputId": "55e4ac21-a0d6-47f5-abfd-31d3cd5df16a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 29 00:29:08 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff1R6wmYcxIn",
        "outputId": "eae0d07d-a9d3-4926-8130-72e27c2d8c7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3MB 9.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 54.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 51.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 47.0MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHRvF17C7vjB"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "import tensorflow as tf\n",
        "\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxsPFuahqc0e",
        "outputId": "018b6c13-8c68-43b5-983c-9257f4ed6a8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://www.dropbox.com/s/fna7obll05a8dmi/2020USElection.zip\n",
        "!unzip 2020USElection.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 00:29:21--  https://www.dropbox.com/s/fna7obll05a8dmi/2020USElection.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.6.1, 2620:100:601c:1::a27d:601\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.6.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/fna7obll05a8dmi/2020USElection.zip [following]\n",
            "--2020-10-29 00:29:21--  https://www.dropbox.com/s/raw/fna7obll05a8dmi/2020USElection.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com/cd/0/inline/BCJxN3PLlZkBn1lG7F8cZCjNmmi62jG1fpv8FWjQThGTH7bim63SL68wOpcaFIe_uc0LIXrQyXLSZJzluxA3tjUfneQ6gtIJZDYks8u81HH9H8FkDbKX21dDDgWqJIGu8ug/file# [following]\n",
            "--2020-10-29 00:29:22--  https://uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com/cd/0/inline/BCJxN3PLlZkBn1lG7F8cZCjNmmi62jG1fpv8FWjQThGTH7bim63SL68wOpcaFIe_uc0LIXrQyXLSZJzluxA3tjUfneQ6gtIJZDYks8u81HH9H8FkDbKX21dDDgWqJIGu8ug/file\n",
            "Resolving uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com (uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com (uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BCJkz-Kfgr-yI-tdOmjVo-dZ6OJjA3j2Owvx_oh5FNtFw-PBB-CdN5fjsjEZZg2S4qWphSIGFjMNG4dty0WGF6Sx5Orbp2zxAmWjnpfF2D_dz7kSnP14LbyAjKLCBNdRnPk-0XgXqJ1i35D49b_z13IYCRPfelNQTjYVHJcK_4HPF2sn4-xvOrj6UiSUVJXfzCPv3TH8HyBE0BBExHtVyy1sIZSpVSuJVUv1JlUFPMHEs_9oOYYsbrg5XI4IsFMXtBn_RAyoRvaFqk58tIcYEOgpWe0KTLr3jzRbkKLlVOeLjvip4CD40_bK5wn1DxkUUQDbNH6eUj8vodVmAlN8I9qcBb9b6yNozv9smlwPtSXuVA/file [following]\n",
            "--2020-10-29 00:29:23--  https://uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com/cd/0/inline2/BCJkz-Kfgr-yI-tdOmjVo-dZ6OJjA3j2Owvx_oh5FNtFw-PBB-CdN5fjsjEZZg2S4qWphSIGFjMNG4dty0WGF6Sx5Orbp2zxAmWjnpfF2D_dz7kSnP14LbyAjKLCBNdRnPk-0XgXqJ1i35D49b_z13IYCRPfelNQTjYVHJcK_4HPF2sn4-xvOrj6UiSUVJXfzCPv3TH8HyBE0BBExHtVyy1sIZSpVSuJVUv1JlUFPMHEs_9oOYYsbrg5XI4IsFMXtBn_RAyoRvaFqk58tIcYEOgpWe0KTLr3jzRbkKLlVOeLjvip4CD40_bK5wn1DxkUUQDbNH6eUj8vodVmAlN8I9qcBb9b6yNozv9smlwPtSXuVA/file\n",
            "Reusing existing connection to uc1480993e7b1f951589516899d3.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7288468 (7.0M) [application/zip]\n",
            "Saving to: ‘2020USElection.zip’\n",
            "\n",
            "2020USElection.zip  100%[===================>]   6.95M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-10-29 00:29:24 (126 MB/s) - ‘2020USElection.zip’ saved [7288468/7288468]\n",
            "\n",
            "Archive:  2020USElection.zip\n",
            "  inflating: 2020USElection-BreakSentence.csv  \n",
            "  inflating: 2020USElectiontop5.csv  \n",
            "  inflating: 2020USElectionTranscript.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrjiL7cAvPXy"
      },
      "source": [
        "## Prepping the data ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9a4H8P2Z3-k"
      },
      "source": [
        "df = pd.read_csv(\"/content/2020USElection-BreakSentence.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoiYHFTAabkm",
        "outputId": "611323d7-6a8e-4475-ce8a-36eee91764de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>name</th>\n",
              "      <th>file</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Bernie Sanders</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>We must come together to defeat Donald Trump, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Joe Biden</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>I’ll see you on Thursday.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Kamala Harris</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>In this election, we have a chance to change t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Kamala Harris</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>We’re all in this fight together.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Kamala Harris</td>\n",
              "      <td>2020 Democratic National Convention (DNC) Nigh...</td>\n",
              "      <td>What an awesome responsibility.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                               text\n",
              "0           0  ...  We must come together to defeat Donald Trump, ...\n",
              "1           1  ...                          I’ll see you on Thursday.\n",
              "2           2  ...  In this election, we have a chance to change t...\n",
              "3           3  ...                  We’re all in this fight together.\n",
              "4           4  ...                    What an awesome responsibility.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-BDz5u_CAu",
        "outputId": "9af8e305-ed08-4a1f-b4c8-04f78828c4d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df[\"text\"].values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['We must come together to defeat Donald Trump, and elect Joe Biden and Kamala Harris as our next President and Vice President.',\n",
              "       'I’ll see you on Thursday.',\n",
              "       'In this election, we have a chance to change the course of history.',\n",
              "       ..., 'We’re going to be in Detroit Monday night.',\n",
              "       'Come join us Monday night.', 'I’ll see you later.'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GadvqCTEz2wa"
      },
      "source": [
        "## One Hot Encoding of Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9lSZVynadU9"
      },
      "source": [
        "names = df[\"name\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkVgLzkBYcdZ"
      },
      "source": [
        "num_categories = len(names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_peqdAe5DK3"
      },
      "source": [
        "i, m = pd.factorize(df[\"name\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-743LVZgAHD",
        "outputId": "e4111162-a10b-4710-be3a-c32b40e51af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "m"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Bernie Sanders', 'Joe Biden', 'Kamala Harris', 'Donald Trump',\n",
              "       'Mike Pence'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFf4Cvcp18f_",
        "outputId": "964db9ff-6070-45ae-ce25-32304dc23c56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENZ1-H7A1dFp"
      },
      "source": [
        "df[\"cat_num\"]=i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wMCXDkG5KQN"
      },
      "source": [
        "labels = tf.one_hot(i, depth=len(m))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SO272amgfIE"
      },
      "source": [
        "(train_df, others)=train_test_split(df,shuffle=True,test_size=0.4, stratify=df['name'])\n",
        "(val_df, test_df)=train_test_split(others,shuffle=True,test_size=0.5, stratify=others['name'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za8YNFhWyxR4",
        "outputId": "ced82a25-0f4f-4b99-c899-cd080711f337",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(train_df))\n",
        "print(len(val_df))\n",
        "print(len(test_df))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53659\n",
            "17887\n",
            "17887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdaB2sdPqp2k"
      },
      "source": [
        "X_train = train_df[\"text\"].astype(str).values\n",
        "y_train = tf.one_hot(train_df[\"cat_num\"], num_categories)\n",
        "X_val = val_df[\"text\"].astype(str).values\n",
        "y_val = tf.one_hot(val_df[\"cat_num\"], num_categories)\n",
        "X_test = test_df[\"text\"].astype(str).values\n",
        "y_test= tf.one_hot(test_df[\"cat_num\"], num_categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M76PiQnNTMw",
        "outputId": "58a2dcf4-b29e-4ee3-bfa2-0f9eecf69a69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53659"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JB0mSmenIaoC"
      },
      "source": [
        "## Tokenizer the text ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AytbBqsmY6X"
      },
      "source": [
        "max_len =100\n",
        "max_features = 20000\n",
        "batch_size=64\n",
        "dims=50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpgEvSIOpkq3"
      },
      "source": [
        "## Token ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7t62hj4qp4l"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd_5QbSNqH3c",
        "outputId": "58ddbe0f-03ba-4a47-c424-ee62ff5c107f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_pad = []\n",
        "for i in X_train[0:(53659-11)]:\n",
        "  encoding = tokenizer.encode_plus(\n",
        "  i,\n",
        "  add_special_tokens=True,\n",
        "  max_length=100, # truncates if len(s) > max_length\n",
        "  return_token_type_ids=True,\n",
        "  return_attention_mask=True,\n",
        "  pad_to_max_length=True, # pads to the right by default\n",
        "  return_tensors=\"tf\"\n",
        "  )\n",
        "  X_train_pad.append(encoding)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM0xWHstGn_C"
      },
      "source": [
        "def encode_text(texts):\n",
        "  results = []\n",
        "  for i in texts:\n",
        "    encoding = tokenizer.encode_plus(\n",
        "    i,\n",
        "    add_special_tokens=True,\n",
        "    max_length=100, # truncates if len(s) > max_length\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True, # pads to the right by default\n",
        "    return_tensors=\"tf\"\n",
        "    )\n",
        "    results.append(encoding)\n",
        "  return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn1SljJTLzTl",
        "outputId": "43d3be9f-1418-4b85-c7d2-426df185ba17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_pad = encode_text(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FA4tP7XNNEl8",
        "outputId": "c7fc3b4d-715d-4245-c207-0408b151c46a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(X_train_pad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53659"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gebhVghKG0SL",
        "outputId": "cc127b26-eeb8-4ec3-db5e-3c8c10549777",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_val_pad = encode_text(X_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiI7cmCINmSn",
        "outputId": "403a084b-8913-4c63-c6e9-36a65dd3f8b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(X_val_pad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G3Q5n2QG4UI",
        "outputId": "48e3d971-5da4-4ebd-8537-e8d1b3e590a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_val_pad[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
              "array([[ 101, 1220,  787, 1231, 1280, 1106, 1474,  117,  789, 1284, 1328,\n",
              "        1106, 1198, 1474, 1380,  119,  102,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 100), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6yQIymyc7xV",
        "outputId": "123f7636-a415-4986-d46d-85734ef1ff4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_pad[0][\"input_ids\"][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
              "array([ 101,  146, 1221, 1128,  787, 1231, 1303, 4476,  119,  102,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqQKVPNUGeZ4",
        "outputId": "3463e23d-7771-4865-8a9d-33c7629374c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train[1].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XsPl0r1fA5e"
      },
      "source": [
        "def create_data(texts, labels):\n",
        "  input_ids = []\n",
        "  attention = []\n",
        "  tokens = []\n",
        "  labels = []\n",
        "  for i in texts:\n",
        "    encoding = tokenizer.encode_plus(\n",
        "    i,\n",
        "    add_special_tokens=True,\n",
        "    max_length=100, # truncates if len(s) > max_length\n",
        "    return_token_type_ids=True,\n",
        "    return_attention_mask=True,\n",
        "    pad_to_max_length=True, # pads to the right by default\n",
        "    return_tensors=\"tf\"\n",
        "    )\n",
        "    input_ids.append(encoding[\"input_ids\"][0])\n",
        "    attention.append(encoding[\"attention_mask\"][0])\n",
        "    tokens.append(encoding[\"token_type_ids\"][0])\n",
        "  \n",
        "  return [input_ids,attention, tokens, labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-N97n93jr5B",
        "outputId": "5fd4665f-2f4a-4ee1-c053-4c3912828040",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = create_data(X_train[0:(53659-11)], y_train[0:(53659-11)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RStfr1zCnsF"
      },
      "source": [
        "Define a generator for TFDataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgQwt3RGBqJt"
      },
      "source": [
        "def gen_dataset(tokenise_text, labels):\n",
        "\n",
        "  def gen():\n",
        "    for i in range(len(tokenise_text)):\n",
        "      train = tokenise_text[i]\n",
        "      yield (\n",
        "                  {\n",
        "                      \"input_ids\": train[\"input_ids\"][0],\n",
        "                      \"attention_mask\": train[\"attention_mask\"][0],\n",
        "                      \"token_type_ids\": train[\"token_type_ids\"][0],\n",
        "                  },\n",
        "                  labels[i],\n",
        "              )\n",
        "  dataset = tf.data.Dataset.from_generator(\n",
        "      gen,\n",
        "      ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.float32),\n",
        "      (\n",
        "          {\n",
        "              \"input_ids\": tf.TensorShape([100]),\n",
        "              \"attention_mask\": tf.TensorShape([100]),\n",
        "              \"token_type_ids\": tf.TensorShape([100]),\n",
        "          },\n",
        "          tf.TensorShape([5]),\n",
        "      ),\n",
        "  )\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtUoCvtVGShC"
      },
      "source": [
        "X_train_dataset = gen_dataset(X_train_pad, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNax3fznGYi0"
      },
      "source": [
        "X_val_dataset = gen_dataset(X_val_pad, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03DcEfL6MEQU",
        "outputId": "d4ed581b-2632-496d-e046-e7d95ddef904",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in X_train_dataset:\n",
        "  print(i)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
            "array([ 101,  146, 1221, 1128,  787, 1231, 1303, 4476,  119,  102,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
            "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(5,), dtype=int64, numpy=array([0, 1, 0, 0, 0])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kH4-8bZIKw-"
      },
      "source": [
        "def gen():\n",
        "    for i in range(len(X_train_pad[0:(53659-11)])):\n",
        "      train = X_train_pad[i]\n",
        "      yield (\n",
        "                  {\n",
        "                      \"input_ids\": train[\"input_ids\"][0],\n",
        "                      \"attention_mask\": train[\"attention_mask\"][0],\n",
        "                      \"token_type_ids\": train[\"token_type_ids\"][0],\n",
        "                  },\n",
        "                  y_train[i],\n",
        "              )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmd6zDbbCrHA"
      },
      "source": [
        "dataset = tf.data.Dataset.from_generator(\n",
        "        gen,\n",
        "        ({\"input_ids\": tf.int32, \"attention_mask\": tf.int32, \"token_type_ids\": tf.int32}, tf.int64),\n",
        "        (\n",
        "            {\n",
        "                \"input_ids\": tf.TensorShape([100]),\n",
        "                \"attention_mask\": tf.TensorShape([100]),\n",
        "                \"token_type_ids\": tf.TensorShape([100]),\n",
        "            },\n",
        "            tf.TensorShape([5]),\n",
        "        ),\n",
        "    )\n",
        "dataset = dataset.shuffle(buffer_size=len(X_train_pad), reshuffle_each_iteration=True).batch(BATCH_SIZE).repeat(-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TYHC7Y7IhHO",
        "outputId": "d51be438-4aeb-4eea-801b-dafe77cdcee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in gen():\n",
        "  print(i)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "({'input_ids': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
            "array([ 101,  138, 1974, 1104, 1172,  119,  102,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "          0], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
            "array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(100,), dtype=int32, numpy=\n",
            "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>}, <tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 1., 0.], dtype=float32)>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBjknbW2bi2s",
        "outputId": "d0981359-4011-4a6d-b809-323d7b73f043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(X_train_pad[0][\"input_ids\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va40PtNewUVe"
      },
      "source": [
        "## Model ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_Y_u1Icqzqj",
        "outputId": "de115454-f730-46b8-c676-e98592242260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME, num_labels=len(m), return_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertForSequenceClassification: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier', 'dropout_151']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4M0zsVsHea4",
        "outputId": "02c1b2b5-a0b4-47e8-c218-c60b8a46339e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(X_train_pad)/16\n",
        "#len(X_train)-3353*16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0625"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qnwuhf_azPbW"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-05, epsilon=1e-08)\n",
        "loss = tf.keras.losses.CategoricalCrossentropy()\n",
        "metric = tf.keras.metrics.CategoricalCrossentropy(name='accuracy')\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=[metric])\n",
        "\n",
        "train_steps = len(X_train_pad)//BATCH_SIZE\n",
        "EPOCHS = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1-hEu6jM8YZ"
      },
      "source": [
        "history = model.fit(dataset, \n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=train_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6hKcUrruLj_",
        "outputId": "84d910e5-73ef-4e34-b7ee-1e7abbc9940c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_train_dataset = X_train_dataset.shuffle(buffer_size=len(X_train_pad), reshuffle_each_iteration=True).batch(BATCH_SIZE).repeat(-1)\n",
        "history = model.fit(X_train_dataset, \n",
        "                    epochs=EPOCHS,\n",
        "                    steps_per_epoch=train_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1352/3353 [===========>..................] - ETA: 11:21 - loss: 7.2641 - accuracy: 7.2641"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1A5vTzyHeIS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}